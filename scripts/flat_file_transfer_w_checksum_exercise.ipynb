{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database.\n",
      "['date_dim_20200725113227.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'date_dim_20200725113227.csv'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--------------------------------------------------\n",
    "#Author: Brandon Chiazza\n",
    "#Version: 1.0\n",
    "#Title: Email script with MD5 Checksum File Exchange\n",
    "#NOTE: you will need to prepare this file for import\n",
    "#-------------------------------------------------\n",
    "\n",
    "#import libraries\n",
    "import email\n",
    "import smtplib\n",
    "import ssl\n",
    "import xlrd\n",
    "import xlwt\n",
    "import s3fs\n",
    "import hashlib #check sum\n",
    "import shutil#zip\n",
    "import time#timestamps\n",
    "import boto3#s3 access\n",
    "import os #used to make a directory for save our files\n",
    "import re #regex library\n",
    "import mysql.connector\n",
    "\n",
    "from mysql.connector import errorcode\n",
    "from shutil import make_archive\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#Step 1. Generate Dimension Files. Steps below. In this example, we will generate just one file. \n",
    "\n",
    "'''identify location of the dimension files. This is up to you, but this is the location \n",
    "where your OUTFILE function in MySQL will post the files'''\n",
    "output_file_location = 'MYSQL_OUTPUT_FILE_LOCATION'\n",
    "\n",
    "# connect to server\n",
    "connection = mysql.connector.connect(user='MYSQL_USERNAME', password='MYSQL_PASSWORD',host='localhost', port ='3306')\n",
    "print('Connected to database.')\n",
    "cursor = connection.cursor()\n",
    "\n",
    "#run the sql file \n",
    "sql_file = \"./dimension_output_example.sql\"\n",
    "\n",
    "with open(sql_file) as f:\n",
    "    cursor.execute(f.read(), multi=True)\n",
    "    \n",
    "#print the results    \n",
    "result = os.listdir(output_file_location)\n",
    "print(result)\n",
    "\n",
    "'''now that you have run your file, you will need to search for it in the folder. \n",
    "The following code is a series of regular experessions that allows you to search for the latest file \n",
    "in a directory based on the timestamp. Then it provides the latest file as the output.'''\n",
    "\n",
    "\n",
    "#example of the file name date_dim_20200725101425.csv\n",
    "files_in_directory = os.listdir(output_file_location)\n",
    "file_regex = re.compile(r'date_dim_\\d{14}.csv$')#regex search for date_dimension file with 14 digits\n",
    "filtered_files = [ x for x in files_in_directory if file_regex.match(x)]\n",
    "sorted_files = sorted(filtered_files,reverse=True)\n",
    "sorted_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200725113227\n"
     ]
    }
   ],
   "source": [
    "#Step 2. Move Files to folder 'checksum'\n",
    "executiontime = str(re.findall('\\d+', sorted_files[0])).replace('[\\'','').replace('\\']','')\n",
    "print(executiontime)\n",
    "\n",
    "directory_name = 'DIRECTORY_FOR_YOUR_FILE'+'DAILY_DIMENSIONS_%s'%(executiontime)\n",
    "\n",
    "os.mkdir(directory_name) #creates folder structure called 'checksum'\n",
    "  \n",
    "os.rename(output_file_location+'/'+sorted_files[0], directory_name+'/'+sorted_files[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date_dim_20200725113227.csv', 'md5_checksum.txt']\n"
     ]
    }
   ],
   "source": [
    "#Step 3. Create check sum procedure\n",
    "#create md5 checksum file .txt\n",
    "def file_as_bytes(file):\n",
    "    with file:\n",
    "        return file.read()\n",
    "\n",
    "md5filecontent = hashlib.md5(file_as_bytes(open(directory_name+'/'+sorted_files[0], 'rb'))).hexdigest()\n",
    "f_name = directory_name+'/'+'md5_checksum.txt'\n",
    "\n",
    "f = open(f_name, \"a\")\n",
    "f.write(md5filecontent)\n",
    "f.close()\n",
    "\n",
    "print (os.listdir(directory_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAILY_DIMENSIONS_20200725113227.zip\n"
     ]
    }
   ],
   "source": [
    "#Step 4: Zip files with checksum in directory called checksum. \n",
    "zipName = directory_name\n",
    "make_archive(zipName, 'zip', root_dir=directory_name)\n",
    "\n",
    "file_regex_zip = re.compile(r'DAILY_DIMENSIONS_\\d{14}.zip$')\n",
    "files_in_directory_zip = os.listdir('DIRECTORY_WHERE_YOU_SAVED_YOUR_ZIP_FILE')\n",
    "filtered_files_zip = [ x for x in files_in_directory_zip if file_regex_zip.match(x)]\n",
    "sorted_files_zip = sorted(filtered_files_zip,reverse=True)\n",
    "zipFileName = sorted_files_zip[0]\n",
    "\n",
    "\n",
    "print(zipFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:/DAILY_DIMENSIONS_20200725113227.zip\n",
      "lab-03\n",
      "DAILY_DIMENSIONS_20200725113227.zip\n",
      "Successfull uploaded file to location: s3/lab-03/DAILY_DIMENSIONS_20200725113227.zip\n"
     ]
    }
   ],
   "source": [
    "#Step 5: Load zipped package into AWS S3 with checksum.\n",
    "s3pathName = 'S3_BUCKET_NAME'  #specify name of your s3 bucket\n",
    "zipFileNameFullPath = directory_name+'.zip'\n",
    "\n",
    "#print inputs for s3\n",
    "print(zipFileNameFullPath)\n",
    "print(s3pathName)\n",
    "print(zipFileName)\n",
    "\n",
    "#connect and load the file to s3\n",
    "s3Resource = boto3.resource('s3')\n",
    "s3Resource.meta.client.upload_file(zipFileNameFullPath, s3pathName, zipFileName)\n",
    "\n",
    "#print success message\n",
    "print(\"Successfull uploaded file to location: \"+str('s3/%s/%s'%(s3pathName,zipFileName)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
